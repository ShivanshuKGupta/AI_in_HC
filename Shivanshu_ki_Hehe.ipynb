{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivanshuKGupta/AI_in_HC/blob/main/Shivanshu_ki_Hehe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkyAGxczO5Rw"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vPqpoQFdPVco"
      },
      "outputs": [],
      "source": [
        "!pip install deeplake\n",
        "# !pip install tqdm\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK9ktS8yO9lf",
        "outputId": "f00c5edd-a7b2-4a4e-db42-12b54eaf73de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARnJecXJZMsk"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mp_qLs8KaxeU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# CONSTANTS ================================================\n",
        "save_dir = '/content/drive/My Drive/ham_preprocessed_images'\n",
        "# disk_save_dir = '/content/ham_preprocessed_images'\n",
        "image_size = 224\n",
        "num_channels = 3\n",
        "num_samples = 10015\n",
        "train_dataset_count = 8000\n",
        "unique_labels = [0, 1, 2, 3, 4, 5, 6]\n",
        "num_classes = len(unique_labels)\n",
        "batch_size = 100\n",
        "skip_preprocessing = True\n",
        "file_size = 100  # The number of images per file\n",
        "# =========================================================\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "# !mkdir -p /content/\n",
        "# !ls \"/content/drive/My Drive/ham_preprocessed_images\"\n",
        "# !cp -r \"/content/drive/My Drive/ham_preprocessed_images\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wTztXyiI1AVU"
      },
      "outputs": [],
      "source": [
        "# def resize_and_save_images_n_labels(dataset):\n",
        "#     for id, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "#         image_save_path = os.path.join(save_dir, f'{id}_image.npy')\n",
        "#         label_save_path = os.path.join(save_dir, f'{id}_label.npy')\n",
        "#         if(os.path.exists(image_save_path) and os.path.exists(label_save_path)):\n",
        "#             skipped_count += 1\n",
        "#             continue\n",
        "#         image = sample['images'].numpy()\n",
        "#         label = sample['lesion_categories'].numpy()\n",
        "\n",
        "#         image_resized = tf.image.resize(image, (image_size, image_size)).numpy()\n",
        "#         image_resized = image_resized / 255.0\n",
        "\n",
        "#         np.save(image_save_path, image_resized)\n",
        "#         np.save(label_save_path, label)\n",
        "\n",
        "# def check_for_corrupt_files():\n",
        "#     corrupt_files = []\n",
        "#     for file in tqdm(os.listdir(save_dir)):\n",
        "#         if os.path.getsize(os.path.join(save_dir, file)) == 0:\n",
        "#             corrupt_files.append(file)\n",
        "#             os.remove(os.path.join(save_dir, file))\n",
        "\n",
        "#     if len(corrupt_files) != 0:\n",
        "#         print(f\"\\n{len(corrupt_files)} corrupt files were found!\")\n",
        "#         print(\"All corrupt files were deleted!\")\n",
        "#         print(\"A repair attempt will be made.\")\n",
        "#         resize_and_save_images_n_labels(ham_ds)\n",
        "#         print(\"Repair complete!\")\n",
        "#         check_for_corrupt_files()\n",
        "#     else:\n",
        "#         print(\"\\nNo corrupt files found!\")\n",
        "\n",
        "# if(not skip_preprocessing):\n",
        "#     try:\n",
        "#         import deeplake\n",
        "#         ham_ds = deeplake.load('hub://activeloop/ham10000')\n",
        "#         resize_and_save_images_n_labels(ham_ds)\n",
        "#         # print(f\"\\n{skipped_count} images were skipped!\")\n",
        "#         check_for_corrupt_files()\n",
        "#         del ham_ds\n",
        "#     except ImportError as e:\n",
        "#         print(f\"{e}. Skipping...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_and_save_images_n_labels(dataset):\n",
        "    for id, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        image_save_path = os.path.join(save_dir, f'{id}_image.npy')\n",
        "        label_save_path = os.path.join(save_dir, f'{id}_label.npy')\n",
        "        if(os.path.exists(image_save_path) and os.path.exists(label_save_path)):\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "        image = sample['images'].numpy()\n",
        "        label = sample['lesion_categories'].numpy()\n",
        "\n",
        "        image_resized = tf.image.resize(image, (image_size, image_size)).numpy()\n",
        "        image_resized = image_resized / 255.0\n",
        "\n",
        "        np.save(image_save_path, image_resized)\n",
        "        np.save(label_save_path, label)\n",
        "\n",
        "def check_for_corrupt_files():\n",
        "    corrupt_files = []\n",
        "    for file in tqdm(os.listdir(save_dir)):\n",
        "        if os.path.getsize(os.path.join(save_dir, file)) == 0:\n",
        "            corrupt_files.append(file)\n",
        "            os.remove(os.path.join(save_dir, file))\n",
        "\n",
        "    if len(corrupt_files) != 0:\n",
        "        print(f\"\\n{len(corrupt_files)} corrupt files were found!\")\n",
        "        print(\"All corrupt files were deleted!\")\n",
        "        print(\"A repair attempt will be made.\")\n",
        "        resize_and_save_images_n_labels(ham_ds)\n",
        "        print(\"Repair complete!\")\n",
        "        check_for_corrupt_files()\n",
        "    else:\n",
        "        print(\"\\nNo corrupt files found!\")\n",
        "\n",
        "if(not skip_preprocessing):\n",
        "    try:\n",
        "        import deeplake\n",
        "        ham_ds = deeplake.load('hub://activeloop/ham10000')\n",
        "        resize_and_save_images_n_labels(ham_ds)\n",
        "        # print(f\"\\n{skipped_count} images were skipped!\")\n",
        "        check_for_corrupt_files()\n",
        "        del ham_ds\n",
        "    except ImportError as e:\n",
        "        print(f\"{e}. Skipping...\")"
      ],
      "metadata": {
        "id": "dtxMcPWuXkdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Labels into labels.npy"
      ],
      "metadata": {
        "id": "6vrlOe8v8nna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import deeplake\n",
        "# ham_ds = deeplake.load('hub://activeloop/ham10000')\n",
        "# labels = ham_ds['lesion_categories'].numpy()\n",
        "# # labels = labels.map(lambda x: x[0])\n",
        "# labels = np.apply_along_axis(lambda x: x[0], 1, labels)\n",
        "# print(f\"{labels=}\")\n",
        "# np.save(os.path.join(save_dir, 'labels.npy'), labels)"
      ],
      "metadata": {
        "id": "6AJd9YUv77cc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ePmuv0EDPls2"
      },
      "outputs": [],
      "source": [
        "# # Loading....\n",
        "# import numpy as np\n",
        "\n",
        "# def load_instance(id: str):\n",
        "#     image = np.load(os.path.join(save_dir, f'{id}_image.npy'))\n",
        "#     label = np.load(os.path.join(save_dir, f'{id}_label.npy'))\n",
        "#     return image, label\n",
        "\n",
        "# image0, label0 = load_instance(2)\n",
        "# print(image0)\n",
        "# print(label0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2P45t93hvnP"
      },
      "source": [
        "# After preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fKe-Juo4Q36N"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# from skimage.io import imread\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# def image_generator(start, end, batch_size):\n",
        "#     indices = [*range(start, end, batch_size)]\n",
        "#     np.random.shuffle(indices)\n",
        "#     for offset in indices:\n",
        "#         stop = min(offset+batch_size, end)\n",
        "#         batch_images = [np.load(os.path.join(save_dir, f'{id}_image.npy')) for id in range(offset, stop)]\n",
        "#         batch_labels = [np.load(os.path.join(save_dir, f'{id}_label.npy'))[0] for id in range(offset, stop)]\n",
        "\n",
        "#         batch_images = preprocess_input(batch_images)\n",
        "#         batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
        "\n",
        "#         batch_images = np.array(batch_images)\n",
        "#         batch_labels = np.array(batch_labels)\n",
        "\n",
        "#         yield batch_images, batch_labels\n",
        "\n",
        "#         del batch_images\n",
        "#         del batch_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sTgLaOQ410jh"
      },
      "outputs": [],
      "source": [
        "# for x in image_generator(0, 10, 2):\n",
        "#     print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I9a563IjVWK_",
        "outputId": "d1fcd939-4fb5-421d-c058-f08231b0b276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_samples=10015\n",
            "[0, 1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "# import os\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# num_samples = len(os.listdir(save_dir))//2\n",
        "# print(f\"{num_samples=}\")\n",
        "# print(unique_labels)\n",
        "\n",
        "# train_generator = image_generator(0, train_dataset_count, batch_size)\n",
        "# val_generator = image_generator(train_dataset_count, num_samples, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D39FiUVY4N5Q"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqzs1TM6k2YL"
      },
      "source": [
        "### Try with SGDC Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4l2-hsXmk5sp"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# # Initialize the SGDClassifier with a hinge loss (which is similar to SVM)\n",
        "# model = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3)\n",
        "\n",
        "# # Train the model using batches\n",
        "# for X_batch, y_batch in tqdm(image_generator(0, train_dataset_count, batch_size), total=train_dataset_count//batch_size+1):\n",
        "#     X_batch = X_batch.reshape(X_batch.shape[0], -1)  # Flatten images if necessary\n",
        "#     model.partial_fit(X_batch, y_batch, classes=unique_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0zSadhwtSrV"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "8dskd5uGk6R5"
      },
      "outputs": [],
      "source": [
        "# # Validate the model\n",
        "# for X_batch, y_batch in tqdm(image_generator(train_dataset_count, num_samples, batch_size), total=(num_samples-train_dataset_count)//batch_size+1):\n",
        "#     X_batch = X_batch.reshape(X_batch.shape[0], -1)  # Flatten images if necessary\n",
        "#     accuracy = model.score(X_batch, y_batch)\n",
        "#     print(f'Validation Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EMFExH2Itwlq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-0aVqaFXwMZ"
      },
      "source": [
        "# Try with a Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WGfrKKkgtX0u"
      },
      "outputs": [],
      "source": [
        "# # Create the dataset using the generator\n",
        "# dataset = tf.data.Dataset.from_generator(\n",
        "#     lambda: image_generator(0, train_dataset_count, batch_size),\n",
        "#     output_signature=(\n",
        "#         tf.TensorSpec(shape=(None, image_size, image_size, num_channels), dtype=tf.float32),\n",
        "#         tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "#     )\n",
        "# )\n",
        "\n",
        "# dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# # dataset = dataset.shuffle(buffer_size=1024).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YAQuIURKYweW"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras import layers, models\n",
        "\n",
        "# model = models.Sequential([\n",
        "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, num_channels)),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(64, activation='relu'),\n",
        "#     layers.Dense(len(unique_labels), activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CwvptsvEiSSH"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.callbacks import Callback\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# class TQDMProgressBar(Callback):\n",
        "#     def __init__(self, total_epochs, total_steps):\n",
        "#         super().__init__()\n",
        "#         self.total_epochs = total_epochs\n",
        "#         self.total_steps = total_steps\n",
        "#         self.progress_bar = None\n",
        "\n",
        "#     def on_train_begin(self, logs=None):\n",
        "#         self.epoch_bar = tqdm(total=self.total_epochs, desc='Epoch Progress', unit='epoch')\n",
        "\n",
        "#     def on_epoch_begin(self, epoch, logs=None):\n",
        "#         self.progress_bar = tqdm(total=self.total_steps, desc=f'Epoch {epoch+1}/{self.total_epochs}', unit='step')\n",
        "\n",
        "#     def on_batch_end(self, batch, logs=None):\n",
        "#         self.progress_bar.update(1)\n",
        "\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         self.progress_bar.close()\n",
        "#         self.epoch_bar.update(1)\n",
        "\n",
        "#     def on_train_end(self, logs=None):\n",
        "#         self.epoch_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SOSTVV8yYzHm"
      },
      "outputs": [],
      "source": [
        "# total_epochs = 10\n",
        "# steps_per_epoch = train_dataset_count // batch_size\n",
        "\n",
        "# print(f\"{total_epochs=}\")\n",
        "# print(f\"{steps_per_epoch=}\")\n",
        "# print(f\"{train_dataset_count=}\")\n",
        "# print(f\"{batch_size=}\")\n",
        "\n",
        "# progress_bar_callback = TQDMProgressBar(total_epochs=total_epochs, total_steps=steps_per_epoch)\n",
        "\n",
        "# # model.fit(dataset, epochs=total_epochs, steps_per_epoch=steps_per_epoch, callbacks=[progress_bar_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VcK3dg1jZ0vm"
      },
      "outputs": [],
      "source": [
        "# total_epochs = 1\n",
        "# steps_per_epoch = train_dataset_count // batch_size\n",
        "\n",
        "# for i in range(10):\n",
        "#     try:\n",
        "#         print(\"epoch:\", i)\n",
        "#         model.fit(dataset, epochs=total_epochs, steps_per_epoch=steps_per_epoch)\n",
        "#     except:\n",
        "#         print(\"Error!!!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BdRLjge0syvN"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras import layers, models\n",
        "\n",
        "# # Load the VGG16 model with pre-trained weights, excluding the top fully connected layers\n",
        "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, num_channels))\n",
        "\n",
        "# # Add custom layers on top of VGG16\n",
        "# model = models.Sequential([\n",
        "#     base_model,\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(256, activation='relu'),\n",
        "#     layers.Dropout(0.5),\n",
        "#     layers.Dense(num_classes, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UJjVAgyK398W"
      },
      "outputs": [],
      "source": [
        "# import traceback\n",
        "\n",
        "# total_epochs = 1\n",
        "# steps_per_epoch = train_dataset_count // batch_size\n",
        "\n",
        "# for i in range(10):\n",
        "#     try:\n",
        "#         print(\"epoch:\", i)\n",
        "#         # model.fit(dataset, epochs=total_epochs, steps_per_epoch=steps_per_epoch)\n",
        "#     except Exception as e:\n",
        "#         print(\"\\n\\nError: \", e)\n",
        "#     except:\n",
        "#         print(\"\\n\\n\\terror !!!!!\\n\")\n",
        "#         traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XxybMmY63_yQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Qj1NpN4Poi"
      },
      "source": [
        "# Trying with VGG without using a generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wkcMzKU44Zfb"
      },
      "outputs": [],
      "source": [
        "# train_dataset = []\n",
        "# train_labels = []\n",
        "# num_samples = 100\n",
        "\n",
        "# for i in range(num_samples):\n",
        "#     image, label = load_instance(i)\n",
        "#     train_dataset.append(image)\n",
        "#     train_labels.append(label[0])\n",
        "\n",
        "# train_dataset = np.array(train_dataset)\n",
        "# train_labels = np.array(train_labels)\n",
        "\n",
        "# print(f\"{train_dataset[:5].shape=}\")\n",
        "# print(f\"{train_labels[:5].shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "d_bQtGHJ4U0s"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Flatten\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_labels_one_hot = to_categorical(train_labels, num_classes=7)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(train_dataset, train_labels_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# model = Sequential([\n",
        "#     vgg_base,\n",
        "#     Flatten(),\n",
        "#     Dense(256, activation='relu'),\n",
        "#     Dense(7, activation='softmax')  # 7 classes for your labels\n",
        "# ])\n",
        "\n",
        "# # Freeze the VGG16 base layers to avoid updating them during training\n",
        "# vgg_base.trainable = False\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "t1zUvNZZ4ytC"
      },
      "outputs": [],
      "source": [
        "# history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yaZ0qfGu4171"
      },
      "outputs": [],
      "source": [
        "# val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "# print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3hWTqSO242KX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aapdu_eb9Ylt"
      },
      "source": [
        "# Trying VGG with data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QlYCCaJY9bOL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, save_dir, labels, batch_size=32, dim=(224, 224, 3), n_classes=7, shuffle=True, start = 0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.save_dir = save_dir\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(start, len(self.labels))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of batches per epoch\n",
        "        return int(np.floor(len(self.labels) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generate one batch of data\n",
        "        indexes = self.indexes[index * self.batch_size:min(len(self.labels), (index + 1) * self.batch_size)]\n",
        "        X, y = self.__data_generation(indexes)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is True\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "        # Generate data for the batch\n",
        "        X = np.empty((self.batch_size, *self.dim))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        for i, idx in enumerate(indexes):\n",
        "            # Load image\n",
        "            X[i,] = np.load(f\"{self.save_dir}/{idx}_image.npy\")\n",
        "            # Load label\n",
        "            y[i] = self.labels[idx]\n",
        "\n",
        "        # One-hot encode labels\n",
        "        y = tf.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
        "        return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP0OuZSG9nVk",
        "outputId": "ac6199e5-2f99-42c3-c1a0-a05a391b04ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_labels[:100]=array([1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 0, 6, 5, 1, 1, 1, 1, 3, 3,\n",
            "       1, 1, 1, 1, 1, 5, 1, 3, 2, 1, 1, 5, 5, 3, 1, 1, 1, 5, 1, 1, 3, 1,\n",
            "       1, 1, 1, 5, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 4, 3, 3, 3, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 1, 1, 1, 6, 3, 5, 1, 6, 2, 1, 1], dtype=uint32)\n",
            "len(train_labels)=8000\n",
            "val_labels[:100]=array([0, 5, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1,\n",
            "       0, 0, 1, 1, 1, 0, 0, 3, 1, 4, 1, 0, 1, 1, 6, 3, 1, 1, 1, 1, 1, 5,\n",
            "       1, 0, 5, 6, 5, 3, 1, 6, 1, 3, 1, 0, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1,\n",
            "       0, 1, 1, 1, 1, 0, 1, 1, 1, 4, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6], dtype=uint32)\n",
            "len(val_labels)=2015\n"
          ]
        }
      ],
      "source": [
        "# batch_size = 32\n",
        "\n",
        "# train_labels = []\n",
        "\n",
        "# for i in tqdm(range(train_dataset_count)):\n",
        "#     label = np.load(os.path.join(save_dir, f'{i}_label.npy'))\n",
        "#     train_labels.append(label[0])\n",
        "import os\n",
        "\n",
        "train_labels = np.load(os.path.join(save_dir, \"labels.npy\"))\n",
        "train_labels, val_labels = train_labels[:train_dataset_count], train_labels[train_dataset_count:]\n",
        "print(f\"{train_labels[:100]=}\")\n",
        "print(f\"{len(train_labels)=}\")\n",
        "print(f\"{val_labels[:100]=}\")\n",
        "print(f\"{len(val_labels)=}\")\n",
        "\n",
        "train_gen = DataGenerator(save_dir=save_dir, labels=train_labels, batch_size=batch_size, shuffle=True, start=0, end = train_dataset_count)\n",
        "val_gen = DataGenerator(save_dir=save_dir, labels=val_labels, batch_size=batch_size, shuffle=False, start=train_dataset_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aP2k2ByP-Npg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b54407-fff4-4266-f1bd-91624b4b2a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "model = Sequential([\n",
        "    vgg_base,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "vgg_base.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ie2IE64B-muX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc35e09-70e1-417e-c7f2-8e15f25eb619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - 2233s 28s/step - loss: 0.9627 - accuracy: 0.6861 - val_loss: 1.2685 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 173s 2s/step - loss: 0.8281 - accuracy: 0.7119 - val_loss: 1.3926 - val_accuracy: 0.6800\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 178s 2s/step - loss: 0.7569 - accuracy: 0.7356 - val_loss: 1.0839 - val_accuracy: 0.7600\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 181s 2s/step - loss: 0.7097 - accuracy: 0.7554 - val_loss: 1.6425 - val_accuracy: 0.6100\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 181s 2s/step - loss: 0.6651 - accuracy: 0.7696 - val_loss: 1.5807 - val_accuracy: 0.6100\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 183s 2s/step - loss: 0.6311 - accuracy: 0.7819 - val_loss: 1.1976 - val_accuracy: 0.6900\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 184s 2s/step - loss: 0.6022 - accuracy: 0.7949 - val_loss: 1.4329 - val_accuracy: 0.6400\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 185s 2s/step - loss: 0.5745 - accuracy: 0.8090 - val_loss: 1.7370 - val_accuracy: 0.5600\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 184s 2s/step - loss: 0.5475 - accuracy: 0.8190 - val_loss: 1.3856 - val_accuracy: 0.6900\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 185s 2s/step - loss: 0.5244 - accuracy: 0.8280 - val_loss: 1.3148 - val_accuracy: 0.7100\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_gen, validation_data=val_gen, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn1Cnkqd-yu1"
      },
      "outputs": [],
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_gen)\n",
        "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqmKhjjUHYSl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try with a new generator"
      ],
      "metadata": {
        "id": "dSpsZDMMSv9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(batch_no):\n",
        "  start_index = batch_no*batch_size\n",
        "  end_index = min(num_samples, (batch_no+1)*batch_size)-1\n",
        "\n",
        "  file_start = start_index//file_size\n",
        "  file_end = end_index//file_size\n",
        "\n",
        "  images = []\n",
        "  s = start_index % file_size\n",
        "  e = s + batch_size -1\n",
        "\n",
        "  while( file_start<=file_end):\n",
        "    file_content = np.load(os.path.join(save_dir, f'{file_start}_batch.npy'))\n",
        "    images.extend(file_content[s:min(file_size, e+1)])\n",
        "    s=0\n",
        "    e-=file_size\n",
        "    file_start+=1\n",
        "\n",
        "  return images\n",
        "\n",
        "\n",
        "generate_data(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rCAX04eSyWy",
        "outputId": "de6c773b-662c-46b9-a05b-ce3b78c09260"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess images into batches of file_size\n",
        "# make a new generator with new logic\n",
        "# try to train a VGG model with small dataset first using it\n",
        "# try with large dataset"
      ],
      "metadata": {
        "id": "ZkN7OwGcVGOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v2P45t93hvnP",
        "o0zSadhwtSrV",
        "G-0aVqaFXwMZ",
        "66Qj1NpN4Poi"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}